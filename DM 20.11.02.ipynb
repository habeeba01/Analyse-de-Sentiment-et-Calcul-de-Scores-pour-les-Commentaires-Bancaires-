{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "968406cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.10/site-packages (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.10/site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./anaconda3/lib/python3.10/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.10/site-packages (from requests) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eac1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code pour scrapper data from apify\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Définir les paramètres de requête\n",
    "url = \"https://api.apify.com/v2/actor-tasks/UG0wXytjHymGDayPP/runs/last/dataset/items\"\n",
    "querystring = {\n",
    "    \"token\": \"apify_api_LAQKhDgf5JE80y0N85WCXWf3p8np5g2SO3JR\",\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "\n",
    "# Envoyer la requête GET\n",
    "response = requests.request(\"GET\", url, params=querystring)\n",
    "\n",
    "    # Extraire les données JSON de la réponse\n",
    "data = response.json()\n",
    "\n",
    "    # Créer un DataFrame pandas à partir des données\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "    # Enregistrer les données dans un fichier Excel\n",
    "df.to_excel(\"CIHReviews.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62e2b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code pour filtrer les colonne\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin d'accès au fichier Excel sur votre bureau\n",
    "chemin_fichier = \"/Users/habibaezzagrani/Desktop/CIHReviews.xlsx\"  # Remplacez \"nom_du_fichier.xlsx\" par le nom de votre fichier Excel\n",
    "\n",
    "# Lire le fichier Excel\n",
    "df = pd.read_excel(chemin_fichier)\n",
    "\n",
    "# Définir la liste des valeurs de recherche\n",
    "valeurs_recherche = ['title', 'categoryName', 'address', 'city', 'url', 'reviewsCount', 'reviewsDistribution', 'name', 'text', 'textTranslated', 'publishedAtDate', 'likesCount', 'reviewerNumberOfReviews', 'stars']\n",
    "\n",
    "# Filtrer les colonnes du DataFrame\n",
    "df_filtre = df[valeurs_recherche]\n",
    "\n",
    "# Créer une liste pour stocker les données filtrées\n",
    "donnees_filtrees = []\n",
    "\n",
    "# Filtrer les données pour chaque valeur de recherche\n",
    "for valeur in valeurs_recherche:\n",
    "    filtered_data = df_filtre[df_filtre.apply(lambda row: valeur in row.astype(str), axis=1)]\n",
    "    donnees_filtrees.append(filtered_data)\n",
    "\n",
    "# Concaténer les données filtrées en un seul DataFrame\n",
    "donnees_filtrees = pd.concat(donnees_filtrees)\n",
    "\n",
    "\n",
    "# Enregistrer les données filtrées dans un nouveau fichier Excel\n",
    "donnees_filtrees.to_excel('CIHReviewsFiltrés.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0e016c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code pour filtrer les caracteres speciaux\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Chemin d'accès au fichier Excel sur votre bureau\n",
    "chemin_fichier = \"/Users/habibaezzagrani/Desktop/DMProject/CIHReviewsFiltrés.xlsx\"  # Remplacez \"nom_du_fichier.xlsx\" par le nom de votre fichier Excel\n",
    "\n",
    "# Lire le fichier Excel\n",
    "df = pd.read_excel(chemin_fichier)\n",
    "\n",
    "# Prétraitement des commentaires\n",
    "def preprocess_comment(comment):\n",
    "    comment = str(comment)  # Convertir en chaîne de caractères si nécessaire\n",
    "    \n",
    "    # Supprimer les émojis\n",
    "    comment = comment.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # Convertir en minuscules\n",
    "    comment = comment.lower()\n",
    "    \n",
    "    # Supprimer la ponctuation et les caractères spéciaux\n",
    "    comment = re.sub(r'[^\\w\\s]', '', comment)\n",
    "    \n",
    "    # Supprimer les espaces supplémentaires\n",
    "    comment = ' '.join(comment.split())\n",
    "    \n",
    "    # Filtrer les commentaires décimaux\n",
    "    if comment.isdecimal():\n",
    "        return ''\n",
    "    \n",
    "    # Filtrer les commentaires commençant par \"CIH\"\n",
    "    if comment.startswith('cih'):\n",
    "        return ''\n",
    "    \n",
    "    return comment\n",
    "\n",
    "# Appliquer le prétraitement aux commentaires de la colonne \"text\"\n",
    "df['text'] = df['text'].apply(preprocess_comment)\n",
    "\n",
    "# Enregistrer le DataFrame mis à jour dans un nouveau fichier Excel\n",
    "df.to_excel('CIHReviewsPreprocessed.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60b13249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données filtrées enregistrées avec succès dans le fichier 'CIHReviewsFiltrés.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "#code pour filtrer les lignes\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin d'accès au fichier Excel sur votre bureau\n",
    "chemin_fichier = \"/Users/habibaezzagrani/Desktop/DMProject/CIHReviewsPreprocessed.xlsx\"  # Remplacez \"nom_du_fichier.xlsx\" par le nom de votre fichier Excel\n",
    "\n",
    "# Lire le fichier Excel\n",
    "df = pd.read_excel(chemin_fichier)\n",
    "\n",
    "# Filtrer les lignes vides (supprimer les lignes avec des commentaires vides)\n",
    "df_filtre = df.dropna(subset=['text'])\n",
    "\n",
    "# Enregistrer les données filtrées dans un nouveau fichier Excel\n",
    "df_filtre.to_excel('CIHReviewsFiltrésFinal.xlsx', index=False)\n",
    "\n",
    "print(\"Données filtrées enregistrées avec succès dans le fichier 'CIHReviewsFiltrés.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62bea42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7447140525cd4fa18281646916e21e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edfcdc261f44117ae2d3ddfaccde450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c486c4b17bab4e46844d00c178958a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#code pour les stop words \n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Chemin d'accès au fichier Excel sur votre bureau\n",
    "chemin_fichier = \"/Users/habibaezzagrani/Desktop/DMProject/CIHReviewsFiltrésFinal.xlsx\"  # Remplacez \"nom_du_fichier.xlsx\" par le nom de votre fichier Excel\n",
    "\n",
    "# Lire le fichier Excel\n",
    "df = pd.read_excel(chemin_fichier)\n",
    "\n",
    "# Charger le tokenizer BERT et télécharger les fichiers du modèle si nécessaire\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenizer les commentaires\n",
    "def tokenize_comment(comment):\n",
    "    # Appliquer la tokenization avec WordPiece\n",
    "    tokens = tokenizer.tokenize(comment)\n",
    "    return tokens\n",
    "\n",
    "# Appliquer la tokenization aux commentaires de la colonne \"text\"\n",
    "df['text_tokens'] = df['text'].apply(tokenize_comment)\n",
    "\n",
    "# Enregistrer le DataFrame mis à jour dans un nouveau fichier Excel\n",
    "df.to_excel('CIHReviewsTokenized.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install translate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code pour traduction\n",
    "from translate import Translator\n",
    "\n",
    "translator = Translator(to_lang=\"en\")\n",
    "\n",
    "def translate_to_english(text):\n",
    "    translation = translator.translate(text)\n",
    "    return translation\n",
    "\n",
    "df = pd.read_excel('CIHReviewsTokenized.xlsx')\n",
    "\n",
    "df['colonne_traduite'] = df['text'].apply(translate_to_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329aec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcule du score de chaque commentaire\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Charger le fichier Excel\n",
    "df = pd.read_excel('CIHReviewsTokenized.xlsx')\n",
    "\n",
    "# Instancier le tokenizer et le modèle\n",
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "# Fonction pour calculer le sentiment\n",
    "def calculate_sentiment(text):\n",
    "    tokens = tokenizer.encode(text, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    sentiment = int(torch.argmax(result.logits))+1\n",
    "    return sentiment\n",
    "\n",
    "# Appliquer la fonction calculate_sentiment à la colonne 'textTranslated'\n",
    "df['sentiment'] = df['textTranslated'].astype(str).apply(calculate_sentiment)\n",
    "\n",
    "# Afficher le tableau avec la nouvelle colonne 'sentiment'\n",
    "print(df)\n",
    "df.to_excel('CIHReviewsTokenized_Sentiment.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3762f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcule du totaleScore\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier Excel initial\n",
    "df = pd.read_excel('CIHReviewsTokenized_Sentiment.xlsx')\n",
    "\n",
    "\n",
    "# Calculer le nombre de lignes dans la colonne 'sentiment' groupé par 'address'\n",
    "result = df.groupby('address')['sentiment'].count()\n",
    "\n",
    "# Calculer la somme des valeurs dans la colonne 'sentiment' groupée par 'address'\n",
    "result_sum = df.groupby('address')['sentiment'].sum()\n",
    "\n",
    "# Calculer le totalScore en divisant la somme par le nombre de lignes pour chaque groupe,\n",
    "# en arrondissant à un seul chiffre après la virgule\n",
    "total_score = round(result_sum / result, 1)\n",
    "\n",
    "# Ajouter la colonne 'totalScore' au DataFrame initial\n",
    "df['totalScore'] = df['address'].map(total_score)\n",
    "\n",
    "# Enregistrer les résultats dans un nouveau fichier Excel\n",
    "\n",
    "df.to_excel('CIHTotalScore.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c6408b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2912 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      totalScore\n",
       "0            3.3\n",
       "1            3.3\n",
       "2            3.3\n",
       "3            3.3\n",
       "4            3.3\n",
       "...          ...\n",
       "2907         2.1\n",
       "2908         2.1\n",
       "2909         2.1\n",
       "2910         2.1\n",
       "2911         2.1\n",
       "\n",
       "[2912 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['totalScore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a1ad594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier Excel\n",
    "df = pd.read_excel('/Users/habibaezzagrani/Desktop/DMProject/CIHTotalScore.xlsx')\n",
    "\n",
    "# Supprimer une colonne spécifique\n",
    "#col_to_drop = 'text_tokens'\n",
    "#df = df.drop(col_to_drop, axis=1)\n",
    "col_to_drop = 'text'\n",
    "df = df.drop(col_to_drop, axis=1)\n",
    "col_to_drop = 'name'\n",
    "df = df.drop(col_to_drop, axis=1)\n",
    "col_to_drop = 'stars'\n",
    "df = df.drop(col_to_drop, axis=1)\n",
    "col_to_drop = 'likesCount'\n",
    "df = df.drop(col_to_drop, axis=1)\n",
    "col_to_drop = 'reviewerNumberOfReviews'\n",
    "df = df.drop(col_to_drop, axis=1)\n",
    "# Enregistrer le DataFrame dans un nouveau fichier Excel\n",
    "df.to_excel('/Users/habibaezzagrani/Desktop/DMProject/NVCIHTotalScore.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c1bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code pour merging\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier Excel\n",
    "df = pd.read_excel('/Users/habibaezzagrani/Desktop/DMProject/NVCIHTotalScore.xlsx')\n",
    "\n",
    "# Sélectionner les colonnes à regrouper\n",
    "cols_to_group = ['colonne_traduite', 'publishedAtDate','sentiment']\n",
    "\n",
    "# Regrouper les colonnes par adresse (address) et les rassembler dans des listes\n",
    "grouped_df = df.groupby('address')[cols_to_group].apply(\n",
    "    lambda x: [[ tokens, date,score] for tokens, date,score in zip(\n",
    "         x['colonne_traduite'].tolist(), x['publishedAtDate'].tolist(),x['sentiment'].tolist())]\n",
    ").reset_index()\n",
    "\n",
    "# Fusionner les données regroupées avec le DataFrame d'origine\n",
    "merged_df = pd.merge(df, grouped_df, on='address', how='left')\n",
    "\n",
    "# Supprimer les colonnes d'origine\n",
    "merged_df = merged_df.drop(cols_to_group, axis=1)\n",
    "\n",
    "# Supprimer les lignes en double pour la colonne 'address'\n",
    "merged_df = merged_df.drop_duplicates(subset=['address'])\n",
    "\n",
    "# Enregistrer le DataFrame fusionné dans un nouveau fichier Excel\n",
    "merged_df.to_excel('/Users/habibaezzagrani/Desktop/DMProject/FinalFile.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f92680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (1.12.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp310-none-macosx_10_9_x86_64.whl (143.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp310-cp310-macosx_10_9_x86_64.whl (1.5 MB)\n",
      "Requirement already satisfied: networkx in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: filelock in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: requests in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from torchvision) (1.24.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed torch-2.0.1 torchvision-0.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638d6fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (4.29.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: requests in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from transformers) (2.30.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379a0b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (1.10.0)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.10.1-cp310-cp310-macosx_10_9_x86_64.whl (35.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.1/35.1 MB\u001b[0m \u001b[31m838.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/habibaezzagrani/anaconda3/lib/python3.10/site-packages (1.24.2)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.3-cp310-cp310-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.0\n",
      "    Uninstalling scipy-1.10.0:\n",
      "      Successfully uninstalled scipy-1.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.3 scipy-1.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scipy numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6db3d82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpsycopg2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Load data from Excel file\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "# Load data from Excel file\n",
    "excel_file_path = \"/Users/habibaezzagrani/Desktop/DMProject/CIHTotalScore.xlsx\"\n",
    "sheet_name = \"city\"  # Specify the sheet name if applicable\n",
    "columns_to_load = ['city']  # Specify the column names to load\n",
    "\n",
    "# Read specific columns from Excel into a pandas DataFrame\n",
    "df = pd.read_excel(excel_file_path, sheet_name=sheet_name, usecols=columns_to_load)\n",
    "\n",
    "# Database connection details\n",
    "db_host = \"localhost\"\n",
    "db_name = \"cihdatawarehouse\"\n",
    "db_user = \"habibaezzagrani\"\n",
    "db_password = \"\"\n",
    "db_port = \"5432\"\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host=db_host,\n",
    "    database=db_name,\n",
    "    user=db_user,\n",
    "    password=db_password,\n",
    "    port=db_port\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create the table in PostgreSQL\n",
    "table_name = \"CityDimension\"\n",
    "cur.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} (id SERIAL PRIMARY KEY,city TEXT)\")\n",
    "\n",
    "# Convert DataFrame columns to a list of tuples\n",
    "records = df.to_records(index=False)\n",
    "values = list(records)\n",
    "\n",
    "# Create the insert query\n",
    "insert_query = f\"INSERT INTO {table_name} (column1) VALUES (%s)\"\n",
    "\n",
    "# Execute the insert query with the DataFrame values\n",
    "cur.executemany(insert_query, values)\n",
    "\n",
    "# Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and database connection\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data loaded successfully to PostgreSQL!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
